---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.2.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Parse excel files into a HDF5 file
It builds an an [HDF5 file](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-hdf5) 
with the the *vehicle inputs* & *outpus* (`prop`, `wot`, `cycle`) from accdb.

## To see the full tree
...check the `README.py`,
## to run this notebook in your own jupyter-server
...read instructions on the `README.md`,
## to inspect and get help on the HDF5 file
...read instructions on the `README.md` and consult the `HDF5-API.ipynb` notebook.

```{python tags=c("parameters")}
### Cell tagged as `parameters` for *papermill*.
#
skip_h5_write = False
del_h5_on_start = False  # overriden by `skip_h5_write=True`
```

```{python}
## To autoreload codein python files here.
# %load_ext autoreload
# %autoreload 2

## Add %%black at the top of a cell, and re-evaluate it, 
# to format it before git-commits, and ease diffs.
# %load_ext blackcellmagic
```

```{python}
import functools as ftt
import itertools as itt
import logging
from pathlib import Path
import re
import sys
from typing import Tuple, Dict

from columnize import columnize
import numpy as np
from pandalone import xleash
import qgrid
import pandas as pd
from pandas import HDFStore
import wltp

## Add tests/ into `sys.path` to import `vehdb` module.
#
proj_dir = str(Path(wltp.__file__).parents[1] / "tests")
if proj_dir not in sys.path:
    sys.path.insert(0, proj_dir)

import vehdb

idx = pd.IndexSlice
log = logging.getLogger('CarsDB-inputs.ipynb')
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s|%(levelname)4.4s|%(module)s:[%(funcName)s]:\n  +--> %(message)s', 
    datefmt='%Y-%m-%d,%H:%M:%S',
)
```

```{python}
## DEFINITIONS
#
h5fname = "VehData/WltpGS-msaccess.h5"
c_vehnum, c_case, c_engno, c_n, c_pwot, c_SM, c_ASM = (
    "vehicle_no",
    "case_no",
    "no_engine",
    "n",
    "Pwot",
    "SM",
    "ASM",
)
c_case_id = c_case
```

```{python}
## UNCOMMENT next command & run to DELETE the db-file, and rebuild it.
if not skip_h5_write and del_h5_on_start:
    !rm -f {h5fname}
```

```{python}
vehdb.print_nodes(h5fname)
```

```{python}
# a=xleash.lasso('VehData/calculation_parameter_all.15092019_prog_code_dev.xlsx#calculation_parameter_all!::["df"]')
# b=xleash.lasso('VehData/calculation_parameter_all.20092019.xlsx#calculation_parameter_all!::["df"]')
# bad_cols = (a == b).all()
# bad_cols[~bad_cols]
```

```{python}
vehinputs_excel = (
    Path("VehData/calculation_parameter_all.20092019.xlsx"),
    "calculation_parameter_all",
)
specs = xleash.lasso('%s#%s!::["df"]' % vehinputs_excel)

wots_excel = (Path("VehData/TB_Pwot.20092019.xlsx"), "TB_Pwot")
pwots = xleash.lasso('%s#%s!::["df"]' % wots_excel)
```

## PRE 20190728 COLUMNS
```
vehicle_no  rated_power     v_max  ndv_6               no_of_gears  v_max_4  v_max_10  n_min_drive_set  n95_high   at_s                    
comments    kerb_mass       ndv_1  ndv_7               ng_vmax      v_max_5  v_s_max   n_min_wot        n_max1     above_s                 
pmr_km      test_mass       ndv_2  ndv_8               v_max_ext    v_max_6  n_vmax    f_dsc_req        n_max2     vmax_determined_by_n_lim
pmr_tm      rated_speed     ndv_3  ndv_9               v_max_1      v_max_7  f0        Pres_130         n_max3   
IDclass     idling_speed    ndv_4  ndv_10              v_max_2      v_max_8  f1        Pres_130_Prated  n_max_wot
class       v_max_declared  ndv_5  v_max_transmission  v_max_3      v_max_9  f2        n95_low          below_s  

Index(['no_engine', 'n', 'Pwot', 'Twot', 'Pwot_norm', 'Twot_norm', 'SM', 'ASM',
       'Pavai'],
      dtype='object')
```

```{python}
import qgrid

print(columnize(list(specs.columns), displaywidth=160))
print(pwots.columns)
print(specs[c_vehnum].unique(), specs[c_case].unique())
display(vehdb.grid(specs, fitcols=False), vehdb.grid(pwots))
```

```{python}
def extract_SM_from_pwot(
    pwot, c_n=c_n, c_pwot=c_pwot, c_SM=c_SM, c_ASM=c_ASM
) -> "Tuple(pd.DataFrame, float)":
    """
    Keep just (n, Pwot, ASM) columns & extract SM column as scalar value.
    
    :param pwot:
        the wot-curve dataframe for a single vehicle, with columns::
        
            IX	no_engine	n	Pwot	Twot	Pwot_norm	Twot_norm	SM	ASM	Pavai

    :return:
        wot(without SM), SM
        where `wot` is indexed by engine-speed(n)
    """
    SM = vehdb.get_scalar_column(pwot, c_SM)
    pwot = pwot.set_index(c_n).drop(c_SM, axis=1)

    return pwot, SM


# ## TEST
#extract_SM_from_pwot(pwots.loc[pwots[c_engno] == 3])
```

```{python}
vehresults_excel = ("VehData/gearshift_table_all.20092019.2.xlsx", "gearshift_table_all")
# NOTE: it may take ~5 minute to load ~130 vehicles...
results_df = xleash.lasso('%s#%s!::["df"]' % vehresults_excel)
results_df.shape  # (223_722, 116)
```

```{python}
print(columnize(list(results_df.columns), displaywidth=160))
print(results_df[c_vehnum].unique())
print(results_df[c_case].unique())
```

```{python}
## PATCH V_CAP not included in data
#  but communicated separately by Heinz.
specs.loc[slice(117,121), 'v_cap'] = [55, 55, 80, 100, 110]
```

```{python}
scalar_columns = [c_vehnum, "Description", "case_no", "case_no2", "vehicle_no", "IDclass"]


def store_results_per_car(
    h5db,
    results_df,
    props_group_suffix="prop",
    wot_group_suffix="wot",
    cycle_group_suffix="cycle",
    c_vehnum=c_vehnum,
    c_case_id=c_case,
):
    """
    Populate h5db with results collected from a folder full of (`V123.xls`, ...) exchel-files.
    
        vehicles/
            +--v001/
            |   +--props      (series) scalar inputs & outputs generated by AccDB
            |   +--wot  
            |   +--cycle      ADD: (df) cycle-run generated by AccDB
            +...
    """
    all_cases = results_df[c_case_id].unique()
    log.info("Found %s cases in file %s: %s", len(all_cases), vehresults_excel[0], all_cases)

    base = vehdb.provenance_info(files=[vehinputs_excel[0], vehresults_excel[0]])
    for case, outdf in results_df.groupby(c_case_id):
        vehnum = int(outdf[c_vehnum].unique().squeeze())
        
        log.info(f"+++ Case %s, veh %s (out of %s)...", case, vehnum, len(all_cases))
        try:
            outdf = outdf.set_index('tim')
            outdf, oprops = vehdb.drop_scalar_columns(outdf, scalar_columns)
        except Exception:
            display(vehdb.grid(outdf, fitcols=False))
            raise

        ## Store WOT
        #
        pwot = pwots.loc[pwots[c_engno] == vehnum, :]
        assert pwot.size, (case, vehnum)
        pwot, SM = extract_SM_from_pwot(pwot)
        assert SM and pwot.size, (case, vehnum, SM, pwot)
        pwot_node = vehdb.vehnode(vehnum, wot_group_suffix)
        if not skip_h5_write:
            h5db.put(pwot_node, pwot)
            vehdb.provenir_h5node(
                h5db,
                pwot_node,
                title="Full-load-curve of the test-car, as delivered by Heinz on 13 May 2019",
                files=[wots_excel[0]],
                base=base,
            )


        ## Store INP/OUT props
        #
        props = specs.loc[specs[c_case_id] == vehnum, :].squeeze()
        assert isinstance(props, pd.Series), props
        props.update(pd.Series(oprops))
        props[c_SM] = SM

        props_group = vehdb.vehnode(case, props_group_suffix)
        if not skip_h5_write:
            h5db.put(props_group, pd.Series(props))
            vehdb.provenir_h5node(
                h5db,
                props_group,
                title="Input specs & scalar results produced by AccDB",
                base=base,
            )


        ## Store CYCLE
        #
        cycle_group = vehdb.vehnode(case, cycle_group_suffix)
        if not skip_h5_write:
            h5db.put(cycle_group, outdf)
            vehdb.provenir_h5node(
                h5db,
                cycle_group,
                title="Cycle-run produced by AccDB",
                base=base,
            )

# vehresults_excel = ("VehData/gearshift_table_all.15092019_prog_code_dev.xlsx", "gearshift_table_all")
# with vehdb.openh5(h5fname) as h5db:
#     store_results_per_car(h5db, results_df)
```

```{python}
with vehdb.openh5(h5fname) as h5db:
    store_results_per_car(h5db, results_df)
```

```{python}
## OVERRIDE SOME VEHICLES
#
# vehresults_excel = ("VehData/gearshift_table_all.15092019_prog_code_dev_version-FIXClass12.xlsx", "gearshift_table_all")
# results_df = xleash.lasso('%s#%s!::["df"]' % vehresults_excel)
# results_df.shape  # (34886, 115)
 
# with vehdb.openh5(h5fname) as h5db:
#     store_results_per_car(h5db, results_df)
```

```{python}
vehdb.print_nodes(h5fname)
```

```{python}
# %%time
## COMPRESS x4 HDF5: 339Mb --> 90Mb in ~10s.
#
# !ls -lh {h5fname}
if not skip_h5_write:
    !ptrepack  {h5fname}  --complevel=9 --complib=blosc:blosclz -o {h5fname}.tmp
    !mv  {h5fname}.tmp {h5fname}
# !ls -lh {h5fname}
```

```{python}
## SAMPLE: extract data for a specific vehicle. 
#
caseno = 14
iosr, outdf = vehdb.load_vehicle_nodes(h5fname, caseno, 'prop', 'cycle')
display(iosr, outdf.columns, vehdb.grid(outdf, fitcols=False))
```
